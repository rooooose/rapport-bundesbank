\section{Explication des projets}

\subsection{Projet Gaia}

\paragraph{Contexte}

Le projet GAIA vise à simplifier l'utilisation des rapports de durabilité des entreprises grâce à une plateforme centralisée et à faciliter la recherche en réduisant les efforts manuels. 
Il cherche également à créer une référence fiable pour les informations liées au climat.

Ce projet a été lancé par la Deutsche Bundesbank en réponse à la prise de conscience croissante de l'importance de la finance durable.
En effet, des risques financiers en découlent, et il faut donc en avoir conscience et savoir les gérer.

La motivation derrière le projet GAIA est de fournir aux investisseurs et aux décideurs des informations fiables et cohérentes sur la durabilité des investissements. 
Il s'agit de donner aux investisseurs les moyens de prendre des décisions d'investissement plus éclairées et de mieux comprendre les risques et les opportunités associés aux investissements durables.

La Bundesbank a également pour objectif de promouvoir la stabilité financière en intégrant les risques liés au changement climatique dans ses analyses et en encourageant les investisseurs à intégrer ces risques dans leur propre prise de décision.
\\
L'équipe du projet est composée de membres de la Bundesbank bien sûr, mais se fait surtout en collaboration avec d'autres banques internationales (Banque d'Espagne, Banque Centrale Européenne, etc...).

Concrètement, le projet consiste tout d'abord à récupérer les rapports de durabilité des entreprises, disponibles publiquement en ligne.
Ensuite, le texte et les tableaux / graphiques sont extraits, et les données d'empreinte carbone des entreprises (Scope 1, 2, 3) sont extraites à l'aide de Natural Language Processing (NLP).

\begin{figure}[H]
    \centering
    \includegraphics[width=12cm]{GAIA.png}
    \caption{Mock-up de la plateforme Gaia}
\end{figure}

\paragraph{Antécédents}

Mises à part les spécifications et objectifs de la plateforme qui étaient dejà clairs, rien n'avait été concrètement commencé avant mon arrivée.
\paragraph{Objectif visé}

L'objectif est de présenter une preuve de concept du projet.
Mon principal objectif était donc de développer un crawler qui parcourerait les résultats de recherche Google pour les rapports de durabilité des entreprises majeures dans le monde.
Les PDFs trouvés doivent ensuite être téléchargés. 
Parallèlement, les PDFs/liens trouvés doivent être classés, selon s'ils sont justes ou faux pour une requête donnée.
Une fois que cela serait fait, je devrais présenter mes résultats à l'équipe du projet.

\pagebreak
\subsection{Projet ESCB Exchange}

\paragraph{Contexte}

ESCB signifie Eurosystem/European System of Central Banks. Cela se réfère au système européen de banques centrales. 
L'Eurosystem est composé de la Banque centrale européenne (BCE) et des banques centrales nationales des pays de la zone euro. 

L'ESCB Exchange est un forum permettant aux banques centrales de collaborer autour de données climatiques communes. 
Ce forum favorise l'échange de connaissances, de code et d'applications pour améliorer la valeur analytique des données climatiques utilisées. 
Chaque banque centrale désigne jusqu'à 2 experts en données climatiques pour participer au forum. 
Les rencontres du forum ont lieu chaque mois, et des groupes volontaires et agiles pilotent les sujets d'intérêt commun. 
L'initiative encourage l'échange sur le nettoyage des données, le partage de code et les leçons apprises concernant les données climatiques granulaires (des entreprises).

L'un des sujets abordés lors des forums est notamment le rapprochement de données sur les émissions carbones, censées être identiques mais provenant de différentes sources.
En effet, les banques collectent ces données et les utilisent pour des recherches. Il est donc primordial de choisir la meilleure source de données climatiques.
Ma mission portait exactement là-dessus.

\paragraph{Antécédents}

Concernant le rapprochement de données provenant de différentes sources, un code d'analyses de données en R ainsi qu'une présentation présentant la comparaison avaient déjà été faits.
La comparaison concernait les sources ISS et Carbon 4 Finance, tous deux fournisseurs de données. 

\paragraph{Objectif visé}

Ma mission consistait en la même analyse que celle faite précédemment, sauf qu'au lieu de faire une analyse bilatérale, je devais en faire une trilatérale en ajoutant aux sources précédentes celle de TRUCOST.
Le Powerpoint associé devait également être fait en aval.

\begin{figure}[H]
    \centering
    \includegraphics[width=12cm]{ESCB logos.png}
    \caption{Logos des sources de données à rapprocher}
\end{figure}

\pagebreak

\subsection{Projet CSDB}

\paragraph{Contexte}

CSDB signifie "Central Securities Database". Il s'agit d'une base de données centrale des titres en Allemagne, utilisée pour la surveillance des marchés financiers, le suivi des transactions de titres et la facilitation des processus de règlement-livraison.
Au sein de la DSZ, les chercheurs utilisent cette base de données.
\\

Les datasets sont sous la forme de fichiers CSV et il y en a 1 pour chaque mois de chaque année depuis 2009.
Tous les mois environ, une nouvelle version d'un ou plusieurs de ces datasets peut parfois être générée, avec des nouvelles colonnes, nouvelles valeurs, etc...
Autrement dit, une nouvelle version du dataset de 2022-04 (différente de l'original) peut être créée en Avril 2023.

Pour chaque dataset, 4 variantes doivent être générées : En effet, des normes existent, et chaque groupe de chercheurs possède des droits de lecture différents sur les colonnes du dataset.
Par conséquent, chaque variante possède le même contenu dans ses colonnes, mais les colonnes présentes sont différentes.
Et cela doit être fait dès qu'une nouvelle version d'un dataset existe.
Or, chaque dataset fait plusieurs Go, et actuellement, cette génération des 4 variantes ainsi que la comparaison de chaque nouveau dataset avec sa version originale prend 1 semaine. 
\\

Quand la procédure doit être répétée tous les mois, cette solution n'est pas viable telle quelle et doit être optimisée.

\paragraph{Antécédents}

La situation à mon arrivée était la suivante :

Les nouvelles et les anciennes versions du "même" ensemble de données (par exemple les données 2009-04) étaient comparées après la génération des 4 ensembles de données.
Cela engendre beaucoup d'effort et de temps de calcul évitable.

Les fichiers csv ont été compressés afin de tenter une baisse du temps, ce qui a effectivement beaucoup accéléré le temps de lecture des csv. 
Cependant le temps de compression semblait fortement ralentir le processus. 

La comparaison des datasets comportait trop d'informations (moyenne, médiane de chaque colonne des datasets, et bien d'autres valeurs statistiques), ce qui utilisait très certainement du temps supplémentaire inutile, quand seulement un très bref résultat était attendu.

\paragraph{Objectif visé}

Afin de pouvoir générer les 4 versions de datasets uniquement sur les versions modifiées des jeux de données de la même période, la comparaison doit être réalisée en amont.
De plus, la comparaison doit être optimisée et n'indiquer à la fin que si les datasets sont identiques ou non, et sinon montrer les différences.
\\
% \pagebreak
\subsection{Projet NFiG}

\paragraph{Contexte}

NFiG signifie "pour usage interne seulement" (Nur für internen Gebrauch) et concerne les données des chercheurs du département. 
Ces derniers utilisent Stata, un logiciel de statistiques pour générer des graphiques ou effectuer différentes analyses.
Lorsque ces graphiques doivent être publiés, ils doivent être adaptés de manière à ne plus être confidentiels.

Par conséquent, chaque graphique doit être retrouvé dans le code qui l'a généré, ce qui implique de connaître le fichier stata et la ligne à laquelle l'output est généré.

Le but est donc de retrouver automatiquement où est créé chaque graphe dans le code, ou de manière plus générale, de faciliter leur "traçage".
Or, les exportations peuvent être générées par des boucles, ce qui rend la recherche des noms de fichiers difficile.

\paragraph{Antécédents}

Un code python avait déjà été écrit pour tenter d'automatiser cette recherche, mais n'a pas vraiment réussi.
Des rapports Excel on été faits à la main afin de recenser quel graphique ou autre fichier output a été généré dans quel fichier de code / fichier log et à quelle ligne. 

\paragraph{Objectif visé}

La 1ère tâche qui nous avait été donnée était une première lecture et compréhension du code déjà fait pour rechercher les citations de fichiers générés.

Puis la seconde consistait en la génération automatique d'un rapport en markdown grâce à Python, à partir des fichiers Excel remplis manuellement.

Plus de tâches auraient pu m'être données, mais nous avons préféré avec l'autre stagiaire nous concentrer sur d'autres projets. 
Il était en effet assez difficile de comprendre la personne en charge de ce projet lorsqu'une nouvelle étape devait être commencée, celle-ci expliquant de manière très abstraite sans montrer concrètement de quoi il s'agit.
Nous avions de plus le choix de travailler sur bien d'autres projets aussi intéressants.

\pagebreak

\subsection{Projet de recherche NLP}

\paragraph{Contexte}

Ce projet fait l'objet d'un papier de recherche appelé "Exploiter les grands modèles linguistiques pour extraire les citations de jeux de données et de méthodologies".

Il est utile pour les chercheurs de la Bundesbank de voir facilement quels datasets et méthodologies sont utilisés dans quels papiers de recherche déjà produits. 
En effet, il sera ensuite plus facile pour eux de déterminer quels datasets et méthodologies sont les plus adaptés pour leur recherche. 

Concrètement cela se traduirait par un système de recommandation orienté utilisateur : “Les chercheurs comme vous ont utilisé tels datasets et telles méthodologies” ou encore “Vous avez utilisé tel dataset, celui-ci pourrait aussi vous intéresser”. 

Cela permettrait également d'identifier quels datasets ont débouché sur des résultats de qualité et de manière plus générale, quels datasets sont disponibles pour la communauté de recherche.
Cela confère plus de valeur aux datasets, à savoir des informations de contexte : Comment les datasets sont-ils utilisés, quelles analyses permettent-ils, etc… 

Cela peut aussi permettre d'améliorer les services de la DSZ, qui pourra ainsi proposer des jeux de données plus spécialement adaptés aux besoins des chercheurs.


\paragraph{Antécédents}

Cette idée de recherche et sa valeur ajoutée, ainsi que les observations retirées, avaient déjà été documentées dans un livre écrit par les data scientists et chercheurs du département, portant sur les données dans les papiers de recherche.
Les leçons tirées regroupent entre autres : 

\begin{itemize}
    \item Les datasets ayant un même nom dans le papier de recherche peuvent référer à des datasets en réalité différents
    \item Les datasets mentionnés peuvent se référer à des datasets utilisés dans les recherche, mais aussi simplement cités
\end{itemize}

Ces leçons soulignent la complexité du problème à résoudre.

L'idée est d'utiliser un Large Language Model (LLM) déjà existant de manière à ce qu'il nous donne directement la liste des Datasets / méthodologies mentionnées.
Le LLM utilisé serait par exemple ChatGPT, pour des résultats optimaux.
2 schémas pour la potentielle procédure à suivre ont été faits par un collègue :

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{proto_A_NLP.png}
    \caption{Prototype A du projet de recherche}
\end{figure}

La 1ère idée serait donc de découper les papiers en différents paragraphes, et de demander à ChatGPT de directement donner la liste des Datasets / Méthodologies contenues dans chaque paragraphe.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{proto_B_NLP.png}
    \caption{Prototype B}
\end{figure}

Cette 2ème idée est un peu plus prudente et procède en 2 temps : 1- Demander si qqchose d'intéressant est contenu dans l'extrait
2- Si oui, demander quoi exactement.

Cela pourrait être répété soit avec chaque phrase individuelle, soit avec des extraits plus grands.


\paragraph{Objectif visé}

L'objectif est donc à la fin de réaliser un papier de recherche faisant part de cette expérimentation.
Il s'agit avant tout de savoir utiliser ChatGPT, de savoir lui donner le contexte adapté afin qu'il rende le résultat le plus juste possible.

Concrètement, il faudrait idéalement que Le LLM nous donne la liste exacte de tous les Datasets et Méthodologies utilisés, et qu'il sache reconnaître à quel dataset il est fait référence, même lorsqu'il n'est pas directement mentionné dans un certain extrait, mais qu'il l'a été précédemment.
Ex : "La 1ère vague de données" -> Bonne réponse = la 1ere vague du Dataset X.